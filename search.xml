<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[探索神经网络学习率下降问题]]></title>
    <url>%2Fp%2F3203111967%2F</url>
    <content type="text"><![CDATA[{ "@context": "https://ziyuan.baidu.com/contexts/cambrian.jsonld", "@id": "http://www.mrpanc.com/p/3203111967/", "appid": "1590300728750598", "title": "探索神经网络学习率下降问题", "pubDate": "2018-01-30T19:56:50" } 摘要 在理想情况下，我们希望神经网络从错误中学习的速度越快越好。事实究竟是否如此？本文对其进行了研究和分析。文章主要分为四部分，第一部分引出问题并对产生问题的原因进行了分析；第二部分提出了交叉熵代价函数的概念，从理论和实验两方面对其有效性进行了分析，并将其应用于识别MNIST数据集；第三部分提出了Softmax的概念，从理论上对其有效性进行了分析，并将其应用于识别MNIST数据集，同时分析了在使用时可能出现的数值问题，并提出了解决方法；第四部分对交叉熵代价函数与Softmax的关系进行了分析。 本文所有代码均已上传到Github 公式及符号说明 \(n\)表示输入的训练样本总数 \(x\)表示一个训练样本 \(w\)表示权重 \(b\)表示偏移量 \(z = w^Tx + b\) \(a = \sigma(z) = \frac{1}{1+e^{-z}}\) \(z^L_j = \sum_k w^L_{jk}a^{L-1}_k+b^L_j\) 问题引入 在理想情况下，我们希望神经网络从错误中学习的速度越快越好。那么究竟事实是否是这样呢？我们接下来通过一个小实验进行验证。假设现在要通过神经网络实现这样一个目标：输入\(1\)，输出\(0\)。为了简化实验过程，我们只用一个神经元进行训练。具体实现可见single_neural_network.py训练的神经元结构如下图所示。 在训练时，我们使用二次代价函数以及Sigmoid激活函数。现在假设初始权值\(w=0.6\)，初始偏差\(b=0.9\)。代价函数值和输出值随epoch变化曲线如下图所示。观察曲线可知当权值和偏差初始化为较合适的值时，代价函数值的确下降的很快，学习的速度也很快。 接下来我们设置初始值\(w=2\)，初始偏差\(b=2\)。相比于之前设置的参数，现在初始的误差更大。运行结果可见下图。观察曲线可知在大约前150个epoches，代价函数下降的十分缓慢，学习曲线也十分平缓。这个现象表明初始误差变大之后，学习的速度反而变慢了。这与我们期望的效果截然相反。 那么如何解决这个问题呢？在后续章节，我们会分析问题产生的原因，并据此提出解决方案。 原因分析 首先，我们回顾一下之前训练使用的二次代价函数，表达式如下： \[ C(w, b) = \frac{1}{2n}\sum_x (a-y)^2 \] 在使用梯度下降的过程中，根据 \[ \begin{eqnarray} \frac{\partial C}{\partial w} &amp;=&amp; (a-y)\sigma&#39;(z)x, \label{1}\tag{1} \\ \frac{\partial C}{\partial b} &amp;=&amp; (a-y)\sigma&#39;(z), \label{2}\tag{2} \end{eqnarray} \] 可知，学习率与\(\sigma&#39;(z)\)相关。观察\(\sigma(z)\)和\(\sigma&#39;(z)\)的图像（可见下图），可以看到当神经网络训练的结果趋于\(0\)或是\(1\)时，\(\sigma\)函数曲线就会趋于平坦，\(\sigma&#39;(z)\)变得很小，\(\frac{\partial C}{\partial w}, \frac{\partial C}{\partial b}\)也就随之变小，从而导致学习速度变慢。这就是学习率下降的原因所在。 交叉熵代价函数 介绍 为了解决学习速度变慢的问题，我们引入交叉熵代价函数，针对单个神经元，表达式如下： \[C(w, b) = -\frac{1}{n} \sum_x y\ln(a)+(1-y)\ln(1-a)\] 交叉熵代价函数可以作为神经网络的代价函数的原因有两个： 非负，即\(C &gt; 0\)。 当实际输出接近预计输出时，代价函数\(C\)趋于\(0\)。 那么为什么使用交叉熵代价函数可以解决学习速度降低的问题呢？首先，我们对代价函数关于\(w，b\)求偏导，求导过程如下： \[ \begin{split} \frac{\partial C}{\partial w_j} &amp;= \frac{\partial \left[-\frac{1}{n} \sum_x y\ln a+(1-y)\ln(1-a) \right]}{\partial w_j} \\ &amp;= -\frac{1}{n}\sum_x \left[ y\frac{\partial \ln a}{\partial w_j} + (1-y)\frac{\partial \ln (1-a)}{\partial w_j} \right] \\ &amp;= -\frac{1}{n}\sum_x \left[ \frac{y}{a} \frac{\partial a}{\partial w_j} - \frac{1-y}{1-a}\frac{\partial a}{\partial w_j} \right] \\ &amp;= -\frac{1}{n}\sum_x \left[ y(1-a) \frac{\partial z}{\partial w_j} - a(1-y)\frac{\partial z}{\partial w_j} \right] \\ &amp;= -\frac{1}{n}\sum_x \left[y(1-a)x_j - a(1-y)x_j \right] \\ &amp;= \frac{1}{n}\sum_x (a-y)x_j. \end{split} \label{3}\tag{3} \] 同理可推得 \[\frac{\partial C}{\partial b_j} = \frac{1}{n}\sum_x(a-y). \label{4}\tag{4}\] 根据公式\(\eqref{3}\),\(\eqref{4}\)可以发现学习的速度与\(\sigma\)函数无关，而是由\((a-y)\)控制，即由输出的误差控制，这是一个非常好的特性。误差越大，学习的速度就越快，并且消除了\(\sigma&#39;(z)\)的影响，解决了学习率降低的问题。 使用效果 那么究竟交叉熵代价函数在实际应用中是否真的解决了学习率下降的问题呢？我们接下来通过问题引入中使用的单神经元网络来验证。除了使用交叉熵代价函数替代二次代价函数之外（查看代码），其他参数保持不变，即输入\(x=1\)，学习率\(\alpha=0.15\)，初始权值\(w=0.6\)，初始偏差\(b=0.9\)，预计输出\(y=0\)。 12345678910class CrossEntropyCost(object): @staticmethod def fn(a, y): """返回损失""" return np.sum(np.nan_to_num(-y * np.log(a) - (1 - y) * np.log(1 - a))) @staticmethod def delta(z, a, y): """返回输出层的损失delta""" return a - y 观察下图可以发现与问题引入中的第一个样例结果一样，学习的效果很好。接下来设置初始权值为\(w=2\)，初始偏差\(b=2\)，重新进行实验。 根据下图可以发现对比之前的学习效果，现在的学习速度和最终的学习效果都好了很多。这就是交叉熵代价函数给我们带来的惊喜。当初始的误差较大时，它可以防止学习速度被阻塞，让神经网络可以如我们期望的那样从误差中快速学习。 在多层多神经元网络的应用 上一节中只针对单个神经元网络进行了分析，但是在现实生活中我们使用的往往是多层多神经元网络，接下来我们继续探讨交叉熵代价函数是否在多层多神经元网络上依然有效。假设\(y_1, y_2, \cdots\)是神经元的预计输出，\(a_1^L,a_2^L, \cdots\)是神经元的实际输出，那么二次代价函数与交叉熵代价函数的表达式可见公式\(\eqref{5}\)、公式\(\eqref{6}\)： \[ \begin{eqnarray} C &amp;=&amp; \frac{1}{2n} \sum_x \sum_j (a^L_j-y_j)^2. \label{5}\tag{5} \\ C &amp;=&amp; -\frac{1}{n} \sum_x \sum_j \left[y_j \ln a^L_j + (1-y_j) \ln (1-a^L_j) \right]. \label{6}\tag{6} \end{eqnarray} \] 根据公式\(\eqref{5}\)，计算二次代价函数对\(w^L_{jk}\)的偏导，可得： \[ \begin{split} \frac{\partial C}{\partial w^L_{jk}} &amp;= \frac{\partial C}{\partial a^L_j} \frac{\partial a^L_j}{\partial z^L_j} \frac{\partial z^L_j}{\partial w^L_{jk}} \\ &amp;= \frac{1}{2n} \sum_x 2(a^L_j-y_j)\cdot \sigma&#39;(z^L_j) \cdot a^{L-1}_k \\ &amp;= \frac{1}{n} \sum_x a^{L-1}_k(a^L_j - y_j)\sigma&#39;(z^L_j) \end{split} \label{7}\tag{7} \] 观察公式\(\eqref{7}\)，可以发现与单个神经元的结果相似，学习速度与\(\sigma&#39;(z^L_j)\)相关，导致学习速度下降。接下来我们求交叉熵代价函数关于\(w^L_{jk}\)的偏导，求导过程如下： \[ \begin{split} \frac{\partial C}{\partial w^L_{jk}} &amp;= \frac{\partial C}{\partial a^L_j} \frac{\partial a^L_j}{\partial z^L_j} \frac{\partial z^L_j}{\partial w^L_{jk}} \\ &amp;= -\frac{1}{n} \sum_x \frac{y_j - a^L_j}{a^L_j(1-a^L_j)}\cdot a^L_j(1-a^L_j) \cdot a^{L-1}_k \\ &amp;= \frac{1}{n} \sum_x a^{L-1}_k(a^L_j - y_j) \end{split} \label{8}\tag{8} \] 观察公式\(\eqref{8}\)，可以发现\(\sigma&#39;(z^L_j)\)项消失了，表明交叉熵代价函数不仅对单个神经元网络有效，对于多层多神经元网络也有效。 PS: 如果输出层使用线性神经元，即\(a^L_j = z^L_j\)，那么二次代价函数关于\(w^L_{jk}\)，\(b^L_j\)的偏导为： \[ \begin{eqnarray} \frac{\partial C}{\partial w^L_{jk}} &amp;=&amp; \frac{1}{n} \sum_x a^{L-1}_k (a^L_j-y_j). \label{9}\tag{9} \\ \frac{\partial C}{\partial b^L_{j}} &amp;=&amp; \frac{1}{n} \sum_x (a^L_j-y_j). \label{10}\tag{10} \end{eqnarray} \] 观察公式\(\eqref{9}\), \(\eqref{10}\)可以发现如果输出层使用线性神经，那么二次代价函数将不会带来学习率下降的问题。 MNIST识别 这一节我们将使用交叉熵代价函数来识别MNIST数据集。神经网络实现的细节以及实验代码的设计和运行结果可以查看improved_network.py和learning_slowdown.ipynb，这里就不再赘述。现在我们直接查看使用交叉熵代价函数的效果。参数设置参考前一篇文章神经网络理论介绍及实现，网络隐藏层包含30个神经元，mini-batch的大小设置为10，学习率\(\alpha\)设置为0.5，并且训练30个epoches。 12345678import mnist_loadertraining_data, test_data = mnist_loader.load_data_wrapper(dirpath="../data/")import imporved_network as networknet = network.Network([784, 30, 10], cost=network.CrossEntropyCost)net.large_weight_initializer()net.SGD(training_data, 30, 10, 0.5, \ evaluation_data=test_data, \ monitor_evaluation_accuracy=True) 当使用交叉熵代价函数时，最终的准确率到达了\(95.55\%\)（epoch 18），而使用二次代价函数时，最终的准确率为\(95.29\%\)，提升了\(0.26\%\)。将隐藏层神经元增加到50后，最终准确率到达了\(96.46\%\)（epoch 28），与使用二次代价函数时的准确率\(96.02\%\)相比，增加了\(0.44\%\)。虽然这样看来提升的并不多，但是换个角度来看，错误率从\(3.98\%\)降低到了\(3.54\%\)，错误率较之前降低了约\(11\%\)，还是十分可观的。当隐藏层神经元增加到100后，最终准确率到达了\(97.01\%\)，而二次代价函数的准确率则降低到了\(87.84\%\)。 来源 前几节中，我们分析了交叉熵代价函数为何有效、观察了其应用到MNIST数据集的效果。那么我们不禁想问最初是如何想到这个代价函数的呢？这一章让我们来了解一下交叉熵代价函数的由来。 根据原因分析，我们已经得知使得学习率降低的罪魁祸首是\(\sigma&#39;(z)\)。那么现在的问题就转化为我们能否找到一个代价函数使得该项消失。若能，则对于训练样本\(x\)，\(C=C_x\)将满足 \[ \begin{eqnarray} \frac{\partial C}{\partial w} &amp;=&amp; x_j(a-y), \label{11}\tag{11} \\ \frac{\partial C}{\partial b} &amp;=&amp; (a-y). \label{12}\tag{12} \end{eqnarray} \] 如果能找到满足公式\(\eqref{11}\)，\(\eqref{12}\)的代价函数，那么初始代价越大，学习速度就越快，从而解决学习率下降的问题。已知\(\frac{\partial C}{\partial b}\)，根据链式法则可以推导得： \[ \begin{split} &amp; \because{ \begin{split} \frac{\partial C}{\partial b} &amp;= \frac{\partial C}{\partial a} \frac{\partial a}{\partial b}, \\ \frac{\partial a}{\partial b} &amp;= \sigma&#39;(z) = a(1-a), \end{split}} \\ &amp; \therefore{\frac{\partial C}{\partial a} = \frac{a-y}{a(1-a)}}. \end{split} \label{13}\tag{13} \] 想要得到\(C\)的表达式，只需要对\(\frac{\partial C}{\partial a}\)求积分。求解过程如下： \[ \begin{split} \int \frac{\partial C}{\partial a} = \frac{a-y}{a(1-a)}da &amp;= \int \frac{1}{1-a}da - \int \frac{y}{a(1-a)}da \\ &amp;= -\ln (1-a) - \int y\left(\frac{1}{a} + \frac{1}{1-a}\right)da + \rm constant \\ &amp;= - \ln (1-a) - y\ln a + y \ln (1-a) + \rm constant \\ &amp;= -(y \ln a + (1-y)\ln(1-a)) + \rm constant \end{split} \label{14}\tag{14} \] 公式\(\eqref{14}\)表示单个训练样本\(x\)的代价，要得到总的代价函数，只需要对所有的训练集求和后平均，这样我们就能得到 \[ \begin{eqnarray} C = -\frac{1}{n} \sum_x [y \ln a +(1-y) \ln(1-a)] + {\rm constant}, \label{15}\tag{15}\end{eqnarray} \] 交叉熵代价函数并不是凭空想象出来的，而是根据需要进行推导自然得出的。交叉熵的概念其实最开始是来自于信息论，这边不再展开讨论，如果感兴趣可以浏览维基百科。 Softmax 上一章介绍了交叉熵代价函数，这一章将介绍如何用Softmax解决学习率下降问题。 引入 Softmax提出了一个新的类型的输出层。当我们得到\(z_j^L\)之后，传统的思路是带入激活函数计算作为输出层的输出，而Softmax则是带入Softmax函数进行计算，函数定义如下： \[ a^L_j = \frac{e^{z^L_j}}{\sum_k e^{z^L_k}} \label{16}\tag{16} \] 观察上式，不难得出： \[ \sum_j a^L_j = \frac{\sum_j e^{z^L_j}}{\sum_k e^{z^L_k}} = 1 \label{17}\tag{17} \] 根据公式\(\eqref{16}\)可知所有的输出均为正数，根据公式\(\eqref{17}\)可知所有输出和为\(1\)。结合以上两点，我们可以将Softmax层得到的输出视为一个概率分布。对于很多问题来说，将得到的激活值\(a^L_j\)直接作为输出为\(j\)的概率估计是非常方便的。例如在训练MNIST数据集时，我们可以将\(a^L_j\)视为数字被识别为\(j\)的概率估计。 有效性分析 那么Softmax是如何解决学习速度下降问题的呢？首先，我们先定义一个对数似然代价函数，假设\(x\)表示输入的训练样本，\(y\in\{1,2,\cdots,k\}\)表示预计的输出，那么代价函数可定义为以下形式： \[ C = - \sum_k y_k\log a^L_k \label{18}\tag{18} \] 接下来我们对代价函数的合理性进行分析。以训练MNIST为例，输入一张\(7\)的图片，若网络学习的效果好，则\(a^L_7\)接近\(1\)，\(-\ln a^L_7\)接近\(0\)；反之，若网络学习的效果不好，则\(a^L_7\)接近\(0\)，\(-\ln a^L_7\)接近无穷大。因此，该代价函数是合理的。接下来继续探讨Softmax解决学习率下降的问题。首先求对数似然代价函数关于\(w\)的偏导，求导过程如下： \[ \begin{eqnarray} \frac{\partial C}{\partial w^L_{jk}} = \frac{\partial C}{\partial z_j^L}\frac{\partial z_j^L}{\partial w^L_{jk}}&amp;=&amp; \frac{\partial C}{\partial z_j^L}\frac{\partial \left(\sum_k w^L_{jk}a^{L-1}_k + b_j\right)}{\partial w_{jk}^L} \\ &amp;=&amp; a_k^{L-1} \frac{\partial C}{\partial z_j^L} \\ &amp;=&amp; a_k^{L-1} \frac{\partial \left(- \sum_i y_i\ln a^L_i\right)}{\partial z_j^L} \\ &amp;=&amp; - a_k^{L-1} \sum_i y_i \frac{1}{a^L_i} \frac{\partial a_i^L}{\partial z_j^L} \end{eqnarray} \] 基于公式\(\eqref{16}\)，设\(f_i = e^{z^L_i}, g_i = \sum_k e^{z^L_k}\), \[ \begin{split} \because{\frac{dg_i}{dz^L_j} = e^{z_j^L}, \frac{df_i}{dz^L_j} = \begin{cases} e^{z^L_j}, &amp; \text{if $i=j$} \\ 0, &amp; \text{otherwise} \end{cases}} \end{split} \] \[ \begin{split} \therefore{\frac{\partial a_i^L}{\partial z^L_j} = \frac{f_i&#39;g_i-g_i&#39;f_i}{(g_i)^2} = \begin{cases} \frac{e^{z^L_j}\sum_k e^{z^L_k} - e^{z^L_j}e^{z^L_j}}{\left(\sum e^{z^L_k}\right)^2} = \frac{e^{z^L_j}\left(\left(\sum_k e^{z^L_k}\right) - e^{z^L_j}\right)}{\sum_k e^{z^L_k}} = a_j^L(1-a_j^L) &amp; \text{if $i=j$} \\ \frac{0\sum_k e^{z^L_k} - e^{z^L_i}e^{z^L_j}}{\left(\sum_k e^{z^L_k}\right)^2} = -a_i^La_j^L&amp; \text{if $i\neq j$}\end{cases}} \end{split} \label{19} \tag{19} \] \[ \begin{eqnarray} &amp; \therefore{\begin{split}\frac{\partial C}{\partial w^L_{jk}} &amp;= - a_k^{L-1} \sum_i y_i \frac{1}{a^L_i} \frac{\partial a_i^L}{\partial z_j^L} \\ &amp;= - a_k^{L-1}\left( y_j \frac{1}{a^L_j} a^L_j(1-a^L_j) + \sum_{i\neq j} y_i\frac{1}{a^L_i}(-a^L_ia^L_j)\right) \\ &amp;= - a_k^{L-1} \left(y_j - y_ja_j^L - \sum_{i \neq j}y_ia^L_j\right) \\ &amp;= -a_k^{L-1}\left(y_j - a_j^L\sum_i y_i\right)\end{split}} \\ &amp; \because{\sum_i y_i = 1} \\ &amp; \therefore{\frac{\partial C}{\partial w^L_{jk}} = a_k^{L-1}(a_j^L - y_j)} \label{20} \tag{20} \end{eqnarray} \] 同样的可以推出： \[ \frac{\partial C}{\partial b^L_{j}} = a_j^L - y_j \label{21}\tag{21} \] 根据公式\(\eqref{20}\)，\(\eqref{21}\)可知偏导中消除了\(\sigma&#39;(z)\)项，从而保证了我们不会遇到学习率下降的问题。 应用 这一节主要分为三部分，第一部分介绍Softmax具有冗余参数集的特点，第二部分介绍利用Softmax的特点避免在计算时出现数值错误，第三部分介绍如何将Softmax应用于识别MNIST数据集。 Softmax的特点 Softmax有一个不寻常的特点：它有一个“冗余”的参数集。假设我们从\(z_j^L\)中减去了向量\(c\)，那么Softmax函数将变成以下式子： \[ \begin{split} a^L_j = \frac{e^{z^L_j-c}}{\sum_k e^{z^L_k-c}} =\frac{e^{z^L_j}e^c}{\sum_k e^{z^L_k}e^c} =\frac{e^{z^L_j}e^c}{e^c\sum_k e^{z^L_k}} =\frac{e^{z^L_j}}{\sum_k e^{z^L_k}} \end{split}\] 我们可以发现从\(z_j^L\)中减去了向量\(c\)完全不影响函数的预测结果。 Softmax数值问题 以下代码实现了Softmax的计算。当输入的\(|z|\)较小时（如例1），计算并无异常。但是当输入的\(|z|\)较大时（如例2），会出现数值错误。出现数值错误的原因是由于浮点数只有64位，若\(z\)很大，计算\(e^z\)时会得到inf导致上溢出；若\(z\)很小，分母\(\sum_ke^{z_k}=0\)，导致下溢出。 1234import numpy as npdef softmax(z): """传统的softmax""" return np.exp(z) / np.sum(np.exp(z)) 123# 例1z1 = [1, 1.2, 1.6, 1.9]print(softmax(z1)) Output: [ 0.15377223 0.18781783 0.28019128 0.37821866] 1234# 例2z2 = [1000, 1000, 1000, 10000]z3 = [-1000, -1000, -1000, -10000]print(softmax(z2), softmax(z3)) output: [ nan nan nan nan] [ nan nan nan nan] ... RuntimeWarning: overflow encountered in exp ... ... RuntimeWarning: invalid value encountered in true_divide ... 那么应该如何解决呢？根据前一节中Softmax的特性，我们可以让\(z\)减去一个\(c\)（\(c=max(z)\)）。经过处理之后，\(max(z-c)=0\)，意味着\(e\)的指数最大为0，解决了计算分子时出现的上溢出的问题；同时也保证了分母中必包含一项为\(1\)，从而保证分母不为\(0\)，解决了下溢出的问题。代码以及运行实例如下： 1234567import numpy as npdef shift_softmax(z): """偏移c=max(z)，避免z过大或过小导致上溢出或下溢出""" c = np.max(z) exp_z = np.exp(z-c) return exp_z / np.sum(exp_z)print(shift_softmax(z2), shift_softmax(z3)) output: [ 0. 0. 0. 1.] [ 0.33333333 0.33333333 0.33333333 0. ] 观察上述代码得到的输出，我们可以发现经过Softmax函数计算后可能出现\(a=0\)的情况。当我们根据公式\(\eqref{18}\)计算代价函数\(C\)时（代码），需要计算\(\log a\)，这时就会出现\(\log 0\)的错误（例3）。  123import numpy as npdef cost(a, y): return np.dot(np.log(a), np.transpose(y)) 1234# 例3y = [0, 0, 0, 1]z = [1000, 1000, 1000, 10000]print(cost(shift_softmax(z), y)) Output: nan RuntimeWarning: divide by zero encountered in log 那么如何解决这个问题呢？我们不再计算偏移\(c\)后的Softmax函数，而是直接计算偏移\(c\)后Softmax函数的\(\log\)值（代码及实例）。根据公式\(\eqref{22}\)，可以看到直接计算\(\log\)值的好处在于消除了可能导致\(\log 0\)的项——求和项\(\log \left(\sum_k e^{z^L_k-c}\right)\)中至少有一项为\(1\)，使得求\(\log\)值时不会下溢出，避免了计算\(\log 0\)的悲剧发生。 12345678910111213def log_softmax(z): """根据公式直接求偏移c后softmax的log值，避免出现求log0的情况""" c = np.max(z) return z - c - np.log(np.sum(np.exp(z-c)))def cost2(log_a, y): """输入经过处理的log a""" return np.dot(log_a, np.transpose(y))z = [1000, 1000, 1000, 10000]log_a = log_softmax(z)y = [0, 0, 0, 1]print(cost2(log_a, y)) Output: 0.0 \[ \begin{eqnarray} \log a^L_j &amp;=&amp; \log \frac{e^{z^L_j-c}}{\sum_k e^{z^L_k-c}} \\ &amp;=&amp; \log e^{z^L_j-c} - \log \left(\sum_k e^{z^L_k-c}\right) \\ &amp;=&amp; \left(z^L_j-c\right)-\log \left(\sum_k e^{z^L_k-c}\right) \label{22} \tag{22} \end{eqnarray} \] 使用Softmax识别MNIST数据集 我们在分析Softmax有效性时，已经得到了在应用Softmax时需要用到的两个公式\(\eqref{20}\)，\(\eqref{21}\)，分别表示代价函数\(C\)对\(w\)和对\(b\)的偏导。接下来我们来推导在反向传播时需要用到的输出层误差\(\delta^L_j\)。推导过程如下： \[ \begin{eqnarray} &amp; \begin{split} \delta^L_j = \frac{\partial C}{\partial z_j^L} &amp;=&amp; \frac{\partial \left(- \sum_i y_i\ln a^L_i\right)}{\partial z_j^L} \\ &amp;=&amp; - \sum_i y_i \frac{1}{a^L_i} \frac{\partial a_i^L}{\partial z_j^L} \\ \end{split} \\ &amp; \because \text{Equation } \ref{19} \\ &amp; \therefore \begin{split} \delta^L_j &amp;=&amp; \underbrace{- y_j \frac{1}{a^L_j} a^L_j(1-a^L_j)}_{\color{red}{\text{When } i=j}} - \underbrace{\sum_{i\neq j}y_i\frac{1}{a^L_i} (-a^L_ia^L_j)}_{\color{red}{\text{When } i \neq j}} \\ &amp;=&amp; \underbrace{y_ja^L_j-y_j}_{\color{red}{\text{When } i=j}} + \underbrace{\sum_{i\neq j}y_ia^L_j}_{\color{red}{\text{When } i \neq j}} \\ &amp;=&amp; a_j^L\sum_i y_i - y_j \end{split} \\ &amp; \because \sum_i y_i = 1 \\ &amp; \therefore \delta^L_j=a^L_j-y_j \label{23}\tag{23} \end{eqnarray} \] 推导到这里就结束了。具体实现的代码可以查看Github。参数设置与前一章一致，我们来看看实现的效果如何。 12345678import mnist_loadertraining_data, test_data = mnist_loader.load_data_wrapper(dirpath="../data/")import improved_network as network2net = network2.Network([784, 30, 10], cost=network2.SoftmaxCost)net.large_weight_initializer()net.SGD(training_data, 30, 10, 0.5, \ evaluation_data=test_data, \ monitor_evaluation_accuracy=True) 当隐藏层神经元为30时，准确率为\(95.27\%\)，比使用二次代价函数时的准确率\(95.29\%\)要低一些。当隐藏层神经元增加到50时，准确率为\(96\%\)，依旧比使用二次代价函数时的准确率\(96.02\%\)要低一些。当隐藏层神经元增加到100时，准确率上升到了\(96.59\%\)，高于二次代价函数达到的\(87.84\%\)准确率，但低于使用交叉熵代价函数达到的\(97.01\%\)准确率。 交叉熵代价函数与Softmax的关系 回顾Softmax的代价函数\(\eqref{18}\)，当\(k=2\)时，Softmax的代价函数与交叉熵代价函数形式是一致的。具体来说，当\(k=2\)时，Softmax的代价函数为： \[ C = -\sum_{k=1}^2y_k\log a_k = -y_1\log \frac{e^{z_1}}{e^{z_1}+e^{z_2}} - y_2 \log \frac{e^{z_2}}{e^{z_1}+e^{z_2}} \] 根据Softmax函数参数冗余的特点，我们令\(c=z_1\)，让参数\(z_1, z_2\)都减去\(c\)，可得： \[ \begin{eqnarray} &amp; \begin{split} C &amp;=&amp; -y_1\log \frac{e^{z_1-z_1}}{e^{z_1-z_1}+e^{z_2-z_1}} - y_2 \log \frac{e^{z_2-z_1}}{e^{z_1-z_1}+e^{z_2-z_1}} \\ &amp;=&amp; -y_1 \log \frac{1}{1+e^{z_2-z_1}} - y_2 \log \frac{e^{z_2-z_1}}{1+e^{z_2-z_1}} \\ &amp;=&amp; -y_1 \log \frac{1}{1+e^{z_2-z_1}} - y_2 \log \left (1-\frac{1}{1+e^{z_2-z_1}}\right) \end{split} \\ &amp; \because y_1+y_2 = 1 \\ &amp; \therefore C = -y_1 \log \frac{1}{1+e^{z_2-z_1}} - (1-y_1) \log \left (1-\frac{1}{1+e^{z_2-z_1}}\right) \end{eqnarray} \] 用\(z&#39;\)代替\(z_1-z_2\)，用\(y&#39;\)代替\(y_1\)，最终的形式为： \[ C = -y’ \log \frac{1}{1+e^{-z&#39;}} - (1-y&#39;) \log \left (1-\frac{1}{1+e^{-z&#39;}}\right) \label{24}\tag{24} \] 可以发现公式\(\eqref{24}\)与交叉熵代价函数\(\eqref{6}\)的定义是一致的。 参考文献 Michael A. Nielsen, &quot;Neural network and deep learning&quot;, Determination Press, 2015 Andrew Ng, et al. Softmax Regression]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>neural network</tag>
        <tag>softmax</tag>
        <tag>cross entropy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神经网络理论介绍及实现]]></title>
    <url>%2Fp%2F3045050681%2F</url>
    <content type="text"><![CDATA[{ "@context": "https://ziyuan.baidu.com/contexts/cambrian.jsonld", "@id": "http://www.mrpanc.com/p/3045050681/", "appid": "1590300728750598", "title": "神经网络理论介绍及实现", "pubDate": "2018-01-19T18:35:37", "upDate": "2018-01-26T14:08:00" } 神经网络架构 假设我们的神经网络结构如下图所示，每一个圆都代表一个神经元，第一层被称为输入层，最后一层被称为输出层，位于中间的被称为隐藏层。输入层和输出层的设计往往是非常直接的。以我们需要学习的MNIST数据集为例，想要验证一张手写的数字图片是否为9，假设图片大小为\(64\times64\)，那么就有\(64\times64\)个输入神经元，输出层则只有一个神经元，当输出值大于\(0.5\)时表明输入的图片是9，输出值小于\(0.5\)时，表明输入的图片不是9。 反向传播算法 与回归问题一样，我们也需要通过最小化代价函数来优化预测精度，但是由于神经网络包含了多个隐藏层，每个隐藏层都会输出预测，因此无法通过传统的梯度下降方法来最小化代价函数，而需要逐层考虑误差，并逐层优化。因此，在多层神经网络里面，我们需要通过反向传播算法优化预测精度。 算法流程 在实际应用中，我们一般将反向传播算法与学习算法一起使用，例如Stochatic Gradiant Decent。结合之后的算法流程总结如下： 输入\(n\)个训练样本 对于每一个训练样本\(x_i, i \in \{1,2,\cdots,n\}\)：设置输入层的对应激活值为\(a_i^1\)，然后执行以下步骤： 前向传播： 对于\(l \in \{2, 3, \cdots, L\}\)，分别计算\(z_i^l = w^la_i^{l-1}+b^l\)，\(a_i^l = \sigma(z_i^l)\)。 输出层误差\(\delta^L\)：计算\(\delta_i^L = \nabla_aC.*\sigma&#39;(z_i^L)\) 反向传播误差：对于\(l \in \{L-1, L-2, \cdots, 2\}\)，分别计算\(\delta_i^l = ((w^{l+1})^T\delta_i^{l+1}).*\sigma&#39;(z_i^l)\)。 梯度下降:对于\(l \in \{L, L-1, \cdots, 2\}\)，更新\(w^l \rightarrow w^l-\frac{\alpha}{n}\sum_i\delta_i^l(a^{l-1}_i)^T\)，\(b^l \rightarrow b^l-\frac{\alpha}{n}\sum_i\delta_i^l\)。 理论推导 我们的最终目标是计算\(\min_{w,b}C(w, b)\)，即找到一组参数\((w,b)\)使得代价函数\(C\)最小。因此我们需要计算\(\frac{\partial C}{\partial w}\)和\(\frac{\partial C}{\partial b}\)，从而结合梯度下降算法求得\(C\)的最小值。接下来将以计算\(\frac{\partial C}{\partial w}\)为例进行说明。 计算输出层\(L\)的偏导\(\frac{\partial C}{\partial w^L}\)。根据链式法则，我们可以得到下式： \[ \frac{\partial C}{\partial w^L} = \bbox[yellow,5px,border:2px solid red]{\frac{\partial C}{\partial a^L} \frac{\partial a^L}{\partial z^L}} \frac{\partial z^L}{\partial w^L} \label{1}\tag{1}. \] 计算隐藏层\(L-1\)的偏导\(\frac{\partial C}{\partial w^{L-1}}\)。根据链式法则，我们可以得到下式： \[ \frac{\partial C}{\partial w^{L-1}} = \bbox[yellow,5px,border:2px solid red] {\frac{\partial C}{\partial a^L} \frac{\partial a^L}{\partial z^L}} \frac{\partial z^L}{\partial a^{L-1}}\frac{\partial a^{L-1}}{\partial z^{L-1}} \frac{\partial z^{L-1}}{\partial w^{L-1}} \label{2}\tag{2}. \] 观察公式\(\eqref{1}\)，\(\eqref{2}\)，很明显用红框圈出来的是两个式子共有的一部分，通常我们称之为\(\delta^{L}\)，表达式如公式\(\eqref{3}\)所示。我们可以用\(\delta^{L}\)来计算输出层前一层的偏导。 \[ \begin{equation} \delta^L = \frac{\partial C}{\partial a^L} \frac{\partial a^L}{\partial z^L} \tag{3}\label{3}. \end{equation} \] 同理，隐藏层之间也有类似的共有部分，例如我们可以用\(\delta^{L-1}\)来计算隐藏层最后一层的前一层的偏导，表达式如公式\(\eqref{4}\)所示。 \[ \begin{align} \delta^{L-1} &amp;= \frac{\partial C}{\partial a^L} \frac{\partial a^L}{\partial z^L} \frac{\partial z^L}{\partial a^{L-1}}\frac{\partial a^{L-1}}{\partial z^{L-1}} \\ &amp;= \delta^L \frac{\partial z^L}{\partial a^{L-1}} \frac{\partial a^{L-1}}{\partial z^{L-1}}. \end{align} \label{4}\tag{4} \] 通过公式\(\eqref{3}\)，\(\eqref{4}\)，公式\(\eqref{1}\)，\(\eqref{2}\)可以改写为以下形式： \[ \begin{eqnarray} \frac{\partial C}{\partial w^L} &amp;=&amp; \delta^L \frac{\partial z^L}{\partial w^L} \label{5}\tag{5}, \\ \frac{\partial C}{\partial w^{L-1}} &amp;=&amp; \delta^{L-1} \frac{\partial z^{L-1}}{\partial w^{L-1}} \label{6}\tag{6}. \end{eqnarray} \] 假设激活函数为\(\sigma(z)\)，对公式\((3)\sim(6)\)进行详细的计算。 \[ \begin{eqnarray} \delta^L &amp;=&amp; \frac{\partial C}{\partial a^L} \frac{\partial a^L}{\partial z^L} \\ &amp;=&amp; \nabla_aC \cdot\sigma&#39;(z^L) \label{7}\tag{7}, \\ \\ \delta^{L-1} &amp;=&amp; \delta^L \frac{\partial z^L}{\partial a^{L-1}} \frac{\partial a^{L-1}}{\partial z^{L-1}} \\ &amp;=&amp; \delta^L \frac{\partial (w^La^{L-1}+b^L)}{\partial a^{L-1}} \sigma&#39;(z^{L-1}) \\ &amp;=&amp; \delta^Lw^L\sigma&#39;(z^{L-1}) \label{8}\tag{8}, \\ \\ \frac{\partial C}{\partial w^L} &amp;=&amp; \delta^L \frac{\partial z^L}{\partial w^L} \\ &amp;=&amp; \delta^L \frac{\partial (w^La^{L-1}+b^L)}{\partial w^L} \\ &amp;=&amp; \delta^La^{L-1} \label{9}\tag{9}, \\ \\ \frac{\partial C}{\partial w^{L-1}} &amp;=&amp; \delta^{L-1} \frac{\partial z^{L-1}}{\partial w^{L-1}} \\ &amp;=&amp; \delta^{L-1} \frac{\partial (w^{L-1}a^{L-2}+b^{L-1})}{\partial w^{L-1}} \\ &amp;=&amp; \delta^{L-1}a^{L-2} \label{10}\tag{10}. \end{eqnarray} \] 按照相同的原理，我们可以推得： \[ \begin{align} \frac{\partial C}{\partial b^L} &amp;= \delta^L \frac{\partial z^L}{\partial b^L} \\ &amp;= \delta^L \frac{\partial (w^La^{L-1}+b^L)}{\partial b^L} \\ &amp;= \delta^L \tag{11}. \end{align} \] 将公式\(\eqref{9}\)，\(\eqref{10}\)合并，并用\(l, l+1\)分别替换\(L-1, L\)，则公式\((7)\sim(11)\)可总结为以下三个式子： \[ \begin{align} \delta^l = \begin{cases} \nabla_aC\cdot\sigma&#39;(z^L), &amp; \qquad \text{if $l = L$}, \\ \delta^{l+1}w^{l+1}\sigma&#39;(z^{l}), &amp; \qquad \text{if $l\in\{L-1, L-2, \cdots, 2\}$}, \end{cases} \tag{12} \\ \frac{\partial C}{\partial w^l} = \delta^la^{l-1}, \qquad l \in \{L, L-1, \cdots, 2\} \tag{13}, \\ \frac{\partial C}{\partial b^l} = \delta^l, \qquad l \in \{L, L-1, \cdots, 2\} \tag{14}. \end{align} \] 观察公式\((12)\sim(14)\)可以看出，当前层的代价函数偏导，需要依赖于后一层的计算结果。这也是为什么这个算法的名称叫做反向传播算法。 应用实践 接下来我们将用反向传播算法对MNIST手写数字数据集进行识别。这个问题比较简单，数字共有10种可能，分别为\(\{0, 1, \cdots, 9\}\)，因此是一个10分类问题。 完整代码请参考GitHub: machine-learning-notes(python3.6) 载入数据 首先我们从MNIST手写数字数据集官网下载训练集和测试集，并解压到data文件夹中，data文件夹中应该包含t10k-images.idx3-ubyte, t10k-labels.idx1-ubyte, train-images.idx3-ubyte, train-labels.idx1-ubyte这四个文件。接下来通过python-mnist包对数据集进行导入。如果尚未安装该包，可通过以下命令进行安装： 1pip install python-mnist 使用python-mnist包载入数据，代码如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243import numpy as npfrom mnist import MNISTfrom sklearn.preprocessing import MinMaxScalerdef vectorized_result(j): """ 将数字(0...9)变为one hot向量 输入： j: int，数字(0...9) 输出： e: np.ndarray, 10维的向量，其中第j位为1，其他位都为0。 """ e = np.zeros((10, 1)); e[j] = 1.0 return edef load_data_wrapper(dirpath): """ 载入mnist数字识别数据集，并对其进行归一化处理 输入： dirpath: str, 数据所在文件夹路径 输出： training_data: list, 包含了60000个训练数据集，其中每一个数据由一个tuple '(x, y)'组成， x是训练的数字图像，类型是np.ndarray, 维度是(784,1) y表示训练的图像所属的标签，是一个10维的one hot向量 test_data: list, 包含了10000个测试数据集，其中每一个数据由一个tuple '(x, y)'组成， x是测试的数字图像，类型是np.ndarray, 维度是(784,1) y表示测试的图像所属标签，int类型，是一个(0...9)的数字 """ mndata = MNIST(dirpath) tr_i, tr_o = mndata.load_training() te_i, te_o = mndata.load_testing() min_max_scaler = MinMaxScaler() tr_i = min_max_scaler.fit_transform(tr_i) te_i = min_max_scaler.transform(te_i) training_inputs = [np.reshape(x, (784, 1)) for x in tr_i] training_outputs = [vectorized_result(y) for y in tr_o] training_data = list(zip(training_inputs, training_outputs)) test_inputs = [np.reshape(x, (784, 1)) for x in te_i] test_data = list(zip(test_inputs, te_o)) return training_data, test_datatraining_data, test_data = load_data_wrapper("../data/") 执行时，你可能会遇到下面的错误： 1FileNotFoundError: [Errno 2] No such file or directory: '../data/t10k-images-idx3-ubyte' 这是因为python-mnist包中批量载入数据集时默认的文件名为t10k-images-idx3-ubyte，而从官网下载的数据集文件名为t10k-images.idx3-ubyte，因此只需要修改data文件夹中的文件名即可成功运行。 构建神经网络 网络初始化 搭建网络的基本框架，包括神经网络各个层的数目，以及初始化参数。 12345678910111213class Network(object): def __init__(self, sizes): """初始化神经网络 1. 根据输入，得到神经网络的结构 2. 根据神经网络的结构使用均值为0，方差为1的高斯分布初始化参数权值w和偏差b。 输入： sizes: list, 表示神经网络各个layer的数目，例如[784, 30, 10]表示3层的神经网络。 输入层784个神经元，隐藏层只有1层，有30个神经元，输出层有10个神经元。 """ self.num_layers = len(sizes) self.sizes = sizes self.biases = [np.random.randn(y, 1) for y in sizes[1:]] self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])] 随机梯度下降 123456789101112131415161718192021222324def SGD(self, training_data, epochs, mini_batch_size, alpha, test_data=None): """随机梯度下降 输入： training_data：是由tuples ``(x, y)``组成的list，x表示输入，y表示预计输出 epoches：int, 表示训练整个数据集的次数 mini_batch_size: int, 在SGD过程中每次迭代使用训练集的数目 alpha: float, 学习速率 test_data: 是由tuples ``(x, y)``组成的list，x表示输入，y表示预计输出。 如果提供了``test_data``，则每经过一次epoch，都计算并输出当前网络训练结果在测试集上的准确率。 虽然可以检测网络训练效果，但是会降低网络训练的速度。 """ if test_data: n_test = len(test_data) m = len(training_data) for j in range(epochs): np.random.shuffle(training_data) mini_batches = [training_data[k:k+mini_batch_size] for k in range(0, m, mini_batch_size)] for mini_batch in mini_batches: self.update_mini_batch(mini_batch, alpha) if test_data: print("Epoch &#123;0&#125;: &#123;1&#125; / &#123;2&#125;".format(j, self.evaluate(test_data), n_test)) else: print("Epoch &#123;0&#125; complete".format(j)) 更新权值\(w\)和偏差\(b\) 12345678910111213141516def update_mini_batch(self, mini_batch, alpha): """每迭代一次mini_batch，根据梯度下降方法，使用反向传播得到的结果更新权值``w``和偏差``b`` 输入： mini_batch: 由tuples ``(x, y)``组成的list alpha: int，学习速率 """ nabla_b = [np.zeros(b.shape) for b in self.biases] nabla_w = [np.zeros(w.shape) for w in self.weights] for x, y in mini_batch: delta_nabla_b, delta_nable_w = self.back_prop(x, y) nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)] nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nable_w)] self.weights = [w-(alpha/len(mini_batch))*nw for w, nw in zip(self.weights, nabla_w)] self.biases = [b-(alpha/len(mini_batch))*nb for b, nb in zip(self.biases, nabla_b)] 反向传播 123456789101112131415161718192021222324252627282930313233343536def back_prop(self, x, y): """反向传播 1. 前向传播，获得每一层的激活值 2. 根据输出值计算得到输出层的误差``delta`` 3. 根据``delta``计算输出层C_x对参数``w``, ``b``的偏导 4. 反向传播得到每一层的误差，并根据误差计算当前层C_x对参数``w``, ``b``的偏导 输入： x: np.ndarray, 单个训练数据 y: np.ndarray, 训练数据对应的预计输出值 输出： nabla_b: list, C_x对``b``的偏导 nabla_w: list, C_x对``w``的偏导 """ nabla_b = [np.zeros(b.shape) for b in self.biases] nabla_w = [np.zeros(w.shape) for w in self.weights] # forward prop activation = x activations = [x] zs = [] for b, w in zip(self.biases, self.weights): z = np.dot(w, activation)+b zs.append(z) activation = sigmoid(z) activations.append(activation) # backward prop delta = self.cost_derivative(activations[-1], y)*sigmoid_prime(zs[-1]) nabla_b[-1] = delta nabla_w[-1] = np.dot(delta, activations[-2].transpose()) for l in range(2, self.num_layers): z = zs[-l]; sp = sigmoid_prime(z) delta = np.dot(self.weights[-l+1].transpose(), delta)*sp nabla_b[-l] = delta nabla_w[-l] = np.dot(delta, activations[-l-1].transpose()) return (nabla_b, nabla_w) \(C_x\)对\(a^L\)的偏导 123456789def cost_derivative(self, output_activations, y): """代价函数对a的偏导 输入： output_activations： np.ndarray, 输出层的激活值，即a^L y: np.ndarray, 预计输出值 输出： output_activations-y: list, 偏导值 """ return (output_activations-y) 准确率计算 12345678910def evaluate(self, test_data): """计算准确率，将测试集中的x带入训练后的网络计算得到输出值， 并得到最终的分类结果，与预期的结果进行比对，最终得到测试集中被正确分类的数目 输入： test_data: 由tuples ``(x, y)``组成的list 输出： int, 测试集中正确分类的数据个数 """ test_results = [(np.argmax(self.feed_forward(x)), y) for x, y in test_data] return sum(int(x==y) for (x, y) in test_results) 前馈 根据当前网络训练的结果，对数据\(x\)进行预测 12345678910def feed_forward(self, a): """前馈 输入： a：np.ndarray 输出： a：np.ndarray，预测输出 """ for b, w in zip(self.biases, self.weights): a = sigmoid(np.dot(w, a)+b) return a 激活函数及其导数 1234567def sigmoid(z): """The sigmoid function""" return 1.0/(1.0+np.exp(-z))def sigmoid_prime(z): """Derivative of the sigmoid function""" return sigmoid(z)*(1-sigmoid(z)) 训练 &gt; 训练数据时使用的电脑型号为MacBook Pro (13-inch, Early 2015)，时间仅供参考 训练全部的数据需要一定的时间（用时\(3min53s\)），如果想要快速的查看训练结果，可以取部分训练集和测试集进行训练和测试。 12net = Network([784, 30, 10])net.SGD(training_data, 30, 10, 3.0, test_data=test_data) 输出： Epoch 0: 9121 / 10000 Epoch 1: 9222 / 10000 Epoch 2: 9302 / 10000 Epoch 3: 9369 / 10000 Epoch 4: 9356 / 10000 ...... Epoch 25: 9503 / 10000 Epoch 26: 9508 / 10000 Epoch 27: 9513 / 10000 Epoch 28: 9508 / 10000 Epoch 29: 9529 / 10000 可以看到经过30轮的训练，准确率已经达到了\(95.29\%\)（epoch 29）。作为第一次尝试，这个准确率已经非常令人满意了。 接下来我们增大隐藏层的层数，例如50，来重新训练，看看效果如何。隐藏层增加后，训练速度会变得更加缓慢（用时\(5min15s\)），在等待训练完成的过程中，可以去倒杯茶，放松一下身体。 12net = Network([784, 50, 10])net.SGD(training_data, 30, 10, 3.0, test_data=test_data) 输出： Epoch 0: 9176 / 10000 Epoch 1: 9307 / 10000 Epoch 2: 9416 / 10000 Epoch 3: 9441 / 10000 Epoch 4: 9480 / 10000 ...... Epoch 25: 9584 / 10000 Epoch 26: 9602 / 10000 Epoch 27: 9581 / 10000 Epoch 28: 9582 / 10000 Epoch 29: 9599 / 10000 观察结果可以发现准确率上升到了\(96.02\%\)（epoch 26）。增加隐藏层的确提高了训练的准确率。但是并非一直如此。接下来我们继续增加隐藏层数目，将其设置为100，并设置epoches=60，发现准确率变为了\(87.84\%\)，较之前反而下降了，并且训练的时间也延长到了\(27min 15s\)。因此在设置隐藏层数目时，不能盲目的增加隐藏层数目，否则只会费力不讨好，既降低了准确率，又增加了训练所需时间。比较好的办法是先根据经验设置一个初始值，然后在初始值的基础上慢慢增加，从而得到一个合理的数字。 12net = Network([784, 100, 10])net.SGD(training_data, 60, 10, 3, test_data=test_data) 输出： Epoch 0: 7308 / 10000 Epoch 1: 7572 / 10000 Epoch 2: 7642 / 10000 Epoch 3: 8604 / 10000 Epoch 4: 8644 / 10000 Epoch 5: 8655 / 10000 Epoch 6: 8665 / 10000 ...... Epoch 54: 8772 / 10000 Epoch 55: 8776 / 10000 Epoch 56: 8782 / 10000 Epoch 57: 8784 / 10000 Epoch 58: 8779 / 10000 Epoch 59: 8777 / 10000 参考文献 Michael A. Nielsen, &quot;Neural network and deep learning&quot;, Determination Press, 2015]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>neural network</tag>
        <tag>backward propagation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[继承与组合]]></title>
    <url>%2Fp%2F351146056%2F</url>
    <content type="text"><![CDATA[{ "@context": "https://ziyuan.baidu.com/contexts/cambrian.jsonld", "@id": "http://www.mrpanc.com/p/351146056/", "appid": "1590300728750598", "title": "继承与组合", "pubDate": "2017-05-17T00:01:37", "upDate": "2018-01-23T22:01:00" } 问题引入 现在需要提供这样一个功能： 记录HashSet自从创建以来总共添加的元素个数 为了提供这种功能，直觉上的做法就是继承HashSet，并增加一个变量，用它记录插入的元素数量，并针对该计数值导出一个访问方法。HashSet类包含两个可以增加元素的方法： add， addAll，因此需要覆盖这两个方法。 照此思路可得代码如下： 123456789101112131415161718192021222324public class InstrumentedHashSet&lt;E&gt; extends HashSet&lt;E&gt; &#123; // the number of attempted element insertions private int addCount = 0; public InstrumentedHashSet() &#123; &#125; @Override public boolean add(E e) &#123; addCount++; return super.add(e); &#125; @Override public boolean addAll(Collection&lt;? extends E&gt; c) &#123; addCount += c.size(); return super.addAll(c); &#125; public int getAddCount() &#123; return addCount; &#125;&#125; 为了测试其功能，编写以下测试代码： 123456789101112131415161718192021222324252627public class InstrumentedHashSetTest &#123; private InstrumentedHashSet&lt;String&gt; set; @Before public void setUp() throws Exception &#123; set = new InstrumentedHashSet&lt;&gt;(); &#125; @Test public void add() throws Exception &#123; String s = "Snap"; set.add(s); Assert.assertThat(set, hasItem(s)); &#125; @Test public void addAll() throws Exception &#123; String[] s = &#123;"Snap", "Crackle", "Pop"&#125;; set.addAll(Arrays.asList(s)); Assert.assertThat(set, hasItems(s)); &#125; @Test public void getAddCount() throws Exception &#123; addAll(); Assert.assertEquals(set.getAddCount(), 3); &#125;&#125; 运行结果如下： getAddCount(effectivejava.InstrumentedHashSetTest): expected:&lt;3&gt; but was:&lt;6&gt; false 期望的返回值是3，结果返回的是6。原因在哪？ 看HashSet中add和addAll的实现源码： 1234567891011public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125;public boolean addAll(Collection&lt;? extends E&gt; c) &#123; boolean modified = false; for (E e : c) if (add(e)) modified = true; return modified;&#125; 可以看到addAll方法的实现是循环调用add方法实现的，因此继承了该方法之后，计数值在调用addCount时累加了3，在循环调用add方法时又累加了3，总计增加了6。通过addAll方法增加的每个元素都被计算了两次。这显然跟功能需求不符。 通过上述例子可以看到，继承虽然是实现代码重用的有力手段，但是并非永远是最佳的工具。继承的适用场景和缺点总结如下： ** 适用场景 ** 包的内部适用。在那里，子类和超类的实现都处在同一个程序员的控制之下。 专门为了继承而设计，并具有良好的文档说明的类。 ** 缺点 ** 继承打破了封装性。如果子类依赖于其超类中特定功能的实现细节。当超类发生了变更，那么子类可能会遭到破坏。上述实例也表明了这一点。 组合 上述问题可以通过组合（composition）来解决。组合就是不扩展现有的类，而是在新的类中增加一个私有域，它引用现有类的一个实例。现有的类变成了新类的一个组件。新类中的每个实例方法都可以调用被包含的现有类的实例中对应的方法，并返回它的结果。这被称为转发（forwarding），新类中的方法被称为转发方法（forwarding method）。 接下来用组合和转发的方法实现上述功能。由于Set接口保存了HashSet类的功能特性，因此可以设计一个转发类实现Set接口，并且拥有单个构造器，参数为Set类型。这个包装类就可以用来包装任何Set实现，并且可以结合任何先前存在的构造器一起工作。照此思路可得转发类代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class ForwardingSet&lt;E&gt; implements Set&lt;E&gt; &#123; private final Set&lt;E&gt; s; public ForwardingSet(Set&lt;E&gt; s) &#123; this.s = s; &#125; @Override public int size() &#123; return s.size(); &#125; @Override public boolean isEmpty() &#123; return s.isEmpty(); &#125; @Override public boolean contains(Object o) &#123; return s.contains(o); &#125; @Override public Iterator&lt;E&gt; iterator() &#123; return s.iterator(); &#125; @Override public Object[] toArray() &#123; return s.toArray(); &#125; @Override public &lt;T&gt; T[] toArray(T[] a) &#123; return s.toArray(a); &#125; @Override public boolean add(E e) &#123; return s.add(e); &#125; @Override public boolean remove(Object o) &#123; return s.remove(o); &#125; @Override public boolean containsAll(Collection&lt;?&gt; c) &#123; return s.containsAll(c); &#125; @Override public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return s.addAll(c); &#125; @Override public boolean retainAll(Collection&lt;?&gt; c) &#123; return s.retainAll(c); &#125; @Override public boolean removeAll(Collection&lt;?&gt; c) &#123; return s.removeAll(c); &#125; @Override public void clear() &#123; s.clear(); &#125;&#125; 由于每个InstrumentedSet实例都被另一个Set实例包装起来了，因此InstrumentedSet被称为包装类（wrapper class）。这也正是装饰（Decorator）模式。包装类代码如下： 1234567891011121314151617181920212223public class InstrumentedSet&lt;E&gt; extends ForwardingSet&lt;E&gt; &#123; private int addCount = 0; public InstrumentedSet(Set&lt;E&gt; s) &#123; super(s); &#125; @Override public boolean add(E e) &#123; addCount++; return super.add(e); &#125; @Override public boolean addAll(Collection&lt;? extends E&gt; c) &#123; addCount += c.size(); return super.addAll(c); &#125; public int getAddCount() &#123; return addCount; &#125;&#125; 编写测试代码如下： 1234567891011121314151617181920212223242526272829@FixMethodOrder(MethodSorters.NAME_ASCENDING)public class InstrumentedSetTest &#123; private InstrumentedSet&lt;String&gt; set; @Before public void setUp() throws Exception &#123; set = new InstrumentedSet&lt;&gt;(new TreeSet&lt;String&gt;()); &#125; @Test public void add() throws Exception &#123; String s = "Snap"; set.add(s); Assert.assertThat(set, hasItem(s)); &#125; @Test public void addAll() throws Exception &#123; String[] s = &#123;"Snap", "Crackle", "Pop"&#125;; set.addAll(Arrays.asList(s)); Assert.assertThat(set, hasItems(s)); &#125; @Test public void getAddCount() throws Exception &#123; addAll(); Assert.assertEquals(3, set.getAddCount()); &#125;&#125; 测试通过。 总结 只有当子类真正是超类的子类型时，才适合用继承。也就是说只有当两个类A,B之间确实存在“is-a”关系时，才可使用继承。如果不能完全确定这个关系时，通常情况下B应该包含A的一个私有实例，并且暴露一个较小的、较为简单的API；A本质上不是B的一部分，只是它的实现细节而已。如果不能确保是继承的使用场景，那么为了避免导致脆弱性，可以用组合和转发来代替继承。尤其是存在适当的接口可以实现包装类的时候。包装类不仅比子类更为健壮，而且功能也更强大。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[覆盖equals和hashcode方法]]></title>
    <url>%2Fp%2F1563918912%2F</url>
    <content type="text"><![CDATA[{ "@context": "https://ziyuan.baidu.com/contexts/cambrian.jsonld", "@id": "http://www.mrpanc.com/p/1563918912/", "appid": "1590300728750598", "title": "覆盖equals和hashcode方法", "pubDate": "2017-05-07T20:26:00", "upDate": "2018-01-23T22:01:00" } 覆盖条件 当类具有自己特有的“逻辑相等”概念时（与对象等同的概念不相同），这时就需要覆盖equals方法。 通用约定 查看Object类源码的equals方法，注释上明确的写明了需要遵守的约定如下： 自反性：对于任何非null的引用值x， x.equals(x)将会返回true。 对称性：对于任何非null的引用值x和y，当且仅当y.equals(x)返回true时，x.equals(y)也必须返回true。 传递性：对于任何非null的引用值x、y和z，如果x.equals(y)返回true，并且y.equals(z)也返回true，那么x.equals(z)也必须返回true。 一致性：对于任何非null的引用值x和y，如果equals的比较操作中对象提供的信息没有改变，那么多次调用x.equals(y)就会一致的返回true或false。 原注释如下： It is reflexive: for any non-null reference value x.equals(x) should return true. It is symmetric: for any non-null reference values xand y, x.equals(y) should return true if and only if y.equals(x)returns true. It is transitive: for any non-null reference values x, y, and z, ifx.equals(y)returns trueand y.equals(z)returns true, then x.equals(z)should return true. It is consistent: for any non-null reference values xand y, multiple invocations of x.equals(y)consistently return true or consistently return false, provided no information used in equalscomparisons on the objects is modified. For any non-null reference value x, x.equals(null)should return false. 覆盖方法 例如创建一个Employee对象如下： 1234567public class Employee &#123; private long id; private String firstName; private String lastName; ... // setter and getter method&#125; 假如需要比较两个employee，如果使用默认的equals方法如下： 123456789public class test &#123; public static void main(String[] args) &#123; Employee e1 = new Employee(); Employee e2 = new Employee(); e1.setId(1000); e2.setId(1000); System.out.print(e1.equals(e2)); &#125;&#125; 显然输出结果为false。这时候就满足了我们之前提到的覆盖条件：Employee类需要根据自身属性来判断两个类是否相同。因此可以覆盖equals方法如下： 12345678910@Overridepublic boolean equals(Object o) &#123; if (this == o) return true; if (!(o instanceof Employee)) return false; Employee employee = (Employee) o; return id == employee.id &amp;&amp; (getFirstName() != null ? getFirstName().equals(employee.getFirstName()) : employee.getFirstName() == null &amp;&amp; (getLastName() != null ? getLastName().equals(employee.getLastName()) : employee.getLastName() == null));&#125; 现在再进行测试，即可得到结果为true。 覆盖hashcode方法 覆盖条件 当覆盖了equals方法后，也必须覆盖hashcode方法。如果不覆盖hashcode方法，就会违反Object.hashcode的通用约定，就会导致该类无法结合所有基于散列的集合一起运作，例如Hashmap，Hashset，Hashtable等。 通用约定 在Object类的源码中，对hashcode做了如下约定： 在Java应用程序执行的过程中，无论对同一个对象调用多少次，只要对象的equals方法的比较操作所用到的信息没有被修改，那么该对象的hashcode方法都必须始终返回同一个整数。在同一个应用程序的多次执行过程中，每次执行所返回的整数可以不一致。 如果两个对象通过equals方法比较是相等的，那么分别调用这两个对象的hashcode方法返回的整数必须是相等的。 如果两个对象通过equals方法比较是不等的。分别调用这两个对象的hashcode方法返回的整数不一定要相等。但是程序员应该要意识到给每个不相等的对象产生不同的整数结果可能提高散列表（hash table）的性能。 原文如下： Whenever it is invoked on the same object more than once during an execution of a Java application, the hashCode method must consistently return the same integer, provided no information used in equals comparisons on the object is modified. This integer need not remain consistent from one execution of an application to another execution of the same application. If two objects are equal according to the equals(Object) method, then calling the hashCode method on each of the two objects must produce the same integer result. It is not required that if two objects are unequal according to the java.lang.Object#equals(java.lang.Object) method, then calling the hashCode method on each of the two objects must produce distinct integer results. However, the programmer should be aware that producing distinct integer results for unequal objects may improve the performance of hash tables. 覆盖方法 同样使用Employee类来举例，考虑以下代码： 1234567891011121314public class test &#123; public static void main(String[] args) &#123; Employee e1 = new Employee(); Employee e2 = new Employee(); e1.setId(100); e2.setId(100); // print true System.out.println(e1.equals(e2)); Map&lt;Employee, String&gt; map = new HashMap&lt;&gt;(); map.put(e1, "Jenny"); // print null System.out.println(map.get(e2)); &#125;&#125; 如何两个对象通过equals返回true，那么打印的值应该为Jenny才对。问题就出现在没有重写hashcode方法上。这就是覆盖条件中提到的覆盖了equals方法而没有覆盖hashcode导致的。那么如何覆盖hashcode呢？可简单的通过以下步骤实现： 把某个非零的常数值，比如17保存在一个名为result的int类型的变量中。 对对象中每个关键域（指equals方法中涉及的每个域），完成以下步骤： 为该域计算int类型的散列码c: 若该域是boolean类型，则计算(f?1:0)。 若该域是byte、char、short或int类型，则计算(int) f。 若该域是long类型，则计算(int) (f ^ (f &gt;&gt;&gt; 32))。 若该域是float类型，则计算Float.floatToIntBits(f)。 若该域是double类型，则计算Double.doubleToLongBits(f)，然后按照步骤2.1.3，为得到的long类型值计算散列值。 若该域是一个对象引用，并且该类的equals方法通过递归的调用equals的方式来比较这个域，则同样为这个域递归的调用hashcode。如果需要更复杂的比较，则为这个域计算一个“范式”，然后针对这个范式调用hashcode。如果这个域的值为null，则返回0（或某个其他常数，通常为0）。 若该域是一个数组，则要把每个元素当做单独的域来处理。也就是说，递归地应用上述规则，对每个重要的元素计算一个散列码，然后根据步骤2.2中的做法把这些散列值组合起来。如果数组域中的每个元素都很重要。可以利用发行版本1.5中增加的其中一个Arrays.hashcode方法。 按照下面的公式，把步骤2.1中计算得到的散列码c合并到result中： 1result = 31 * result + c; 返回result。 写完了hashcode方法后，问问自己“相等的实例是否都具有相等的散列码”。要编写单元测试来验证。若相等的实例有着不相等的散列码，则找出原因并修正。 根据上述解决方案可以得到覆盖hashcode如下： 12345678@Overridepublic int hashCode() &#123; int result = 17; result = 31 * result + (int) (id ^ (id &gt;&gt;&gt; 32)); result = 31 * result + getFirstName().hashCode(); result = 31 * result + getLastName().hashCode(); return result;&#125; 再次执行之前的测试即可成功打印Jenny。 谢谢阅读。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
</search>
